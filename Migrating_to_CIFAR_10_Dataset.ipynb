{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Migrating to CIFAR-10 Dataset",
      "provenance": [],
      "collapsed_sections": [
        "vOihTAXHITAi",
        "zpKcttwnrTnT",
        "j3J-NWLSOUwr",
        "LB0DdajjBT2D"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RachelRamirez/CIFAR-10/blob/main/Migrating_to_CIFAR_10_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tLeuxPfOUwh"
      },
      "source": [
        "\"**Simple convnet**\" Architecture with Extremely Limited Data used to Train CNN\n",
        "\n",
        "**Original Author with MNIST:** [fchollet](https://twitter.com/fchollet)<br>\n",
        "Date created: 2015/06/19<br>\n",
        "\n",
        "**Modified to Fashion MNIST** [rachelramirez](https://github.com/RachelRamirez/FashionMNIST_DataAugmentation) 2021/08/25\n",
        "\n",
        "\n",
        "**Modified to CIFAR 10** [rachelramirez](https://github.com/RachelRamirez/CIFAR-10/blob/main/Migrating_to_CIFAR_10_Dataset.ipynb) 2021/09/25\n",
        "\n",
        "\n",
        "**Description:** A simple convnet architecture for training on CIFAR-10 with data augmentation techniques as a Design of Experiment (DOE).\n",
        "\n",
        "Then data is limited to varying levels of sample sizes to view the effect of data augmentation on increasing model accuracy.\n",
        "\n",
        "More features are added to original notebook for residual/error analysis such as confusion matrix and data augmentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOihTAXHITAi"
      },
      "source": [
        "## Google Colab Pro Check Script "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3haQSkOOYVl",
        "outputId": "df33fa10-6a59-4ab9-f3f7-c5c463896259"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Oct 11 13:13:53 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGvYofsKOUwo",
        "outputId": "4de2db1a-5e6f-4be7-c50f-5e50137a7f20"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "from google.colab import files\n",
        "from keras.layers import GaussianNoise\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "\n",
        "print(tf. __version__) \n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from keras.utils.vis_utils import plot_model"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZXBzLMJ7zEP"
      },
      "source": [
        "# CNN Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5U3IqBbq73BY"
      },
      "source": [
        "What is the right combination of number of convolutional layers, filters, and fully connected layers, batch normalization, learning rate,  filters, dropout, weight initialization?\n",
        "\n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4f-ZkVn8NiB"
      },
      "source": [
        "## Import CIFAR Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFrsWfBb8Qc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "0c5a8c2d-d593-403d-aacb-47427fa9d102"
      },
      "source": [
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "input_shape = (32, 32, 3)\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
        "# # Until the end of all analysis I don't really want to look at the real test set results\n",
        "# # I'm overwriting them to make sure I don't accidentally use them\n",
        "\n",
        "print(\"The CIFAR data set has \", x_train.shape[0] , \" training observations, and \", x_test.shape[0], \" test observations.\"  )\n",
        "\n",
        "\n",
        "# # I decide to take 30,000 samples of the training set, and use that to \n",
        "# #  and a VALIDATION Set of up to 10,000 samples, and a FAKE-TEST set of the remaining 10,000\n",
        "# # After Analyzing the best \"Augmentation Effect\" I wil apply it to the \"REAL\" Test DataSet to see if it improved.\n",
        "\n",
        "n = 40000\n",
        "\n",
        "# # Validation Set  \n",
        "x_val = x_train[n:n+10000]\n",
        "y_val = y_train[n:n+10000]\n",
        "\n",
        "\n",
        "# # Finally I change train dataset to first n\n",
        "x_train = x_train[0:n]\n",
        "y_train = y_train[0:n]\n",
        "\n",
        "hist= sn.histplot(y_train)\n",
        "print(hist)\n",
        "# #My holdout Test Set after all the DOE is the original TEST set from dataset\n",
        "\n",
        "\n",
        "print(\"New Training Set shape: \", y_train.shape, \", Val set shape of , \", y_val.shape, \" and test set shape of \", y_test.shape)\n",
        "\n",
        "\n",
        "# Scale images to the [0, 1] range # put into preprocessing model step\n",
        "#x_train = x_train.astype(\"float32\") / 255\n",
        "#x_test = x_test.astype(\"float32\") / 255   \n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "x_val = np.expand_dims(x_val, -1)\n",
        "\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_val.shape[0], \"validation samples\")\n",
        "print(x_test.shape[0], \" test samples saved from the training set\")\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# Try to put in tensor flow shape\n",
        "x_val = tf.stack(x_val)\n",
        "y_val = tf.stack(y_val)\n",
        "\n",
        "\n",
        "# Define Manual Validation Set\n",
        "valid_set = (x_val, y_val)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "170508288/170498071 [==============================] - 4s 0us/step\n",
            "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n",
            "The CIFAR data set has  50000  training observations, and  10000  test observations.\n",
            "AxesSubplot(0.125,0.125;0.775x0.755)\n",
            "New Training Set shape:  (40000, 1) , Val set shape of ,  (10000, 1)  and test set shape of  (10000, 1)\n",
            "x_train shape: (40000, 32, 32, 3, 1)\n",
            "40000 train samples\n",
            "10000 validation samples\n",
            "10000  test samples saved from the training set\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-KCeDf7_imI"
      },
      "source": [
        "## Model Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOfZ5qIo_noz"
      },
      "source": [
        "What is the right combination of number of convolutional layers, filters, and fully connected layers, batch normalization, learning rate,  filters, dropout, weight initialization?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mthJA9Ls_odM"
      },
      "source": [
        "  model = keras.Sequential(\n",
        "  [\n",
        "      keras.Input(shape=input_shape),\n",
        "      layers.experimental.preprocessing.Rescaling(1./255, input_shape=(input_shape)),\n",
        "    #  data_augmentation,   \n",
        "      layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "      layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "      layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "      layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "      layers.Conv2D(128, kernel_size=(3, 3), activation=\"relu\"),\n",
        "      layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "      layers.Flatten(),\n",
        "      #layers.Dropout(0.5),\n",
        "      layers.Dense(num_classes, activation=\"softmax\")\n",
        "  ])\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpKcttwnrTnT"
      },
      "source": [
        "# Augmentation Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJfFyadErbBf"
      },
      "source": [
        "The first part of this experiment is looking at the space for *TrainingSize*, *ValidationSize*, *BatchSize*, and *EpochSize*.  These all likely effect one another (4-way interactions) so a DOE design is used to look at Response Surface Methods.\n",
        "\n",
        "A: BatchSize (10, 100)\n",
        "\n",
        "B: Epochs  (15, 50)\n",
        "\n",
        "C: Training Size (Count)  (100, 1000)\n",
        "\n",
        "D: Validation (as percentage of Training Size)  (20%, 50%) \n",
        "\n",
        "Replicates: 2\n",
        "Center Points: 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5UJ4XGxOUwp"
      },
      "source": [
        "## Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "nW6G-5CNOUwq",
        "outputId": "4193e48f-18ed-45b4-ee8c-7f5d873a6979"
      },
      "source": [
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "input_shape = (32, 32, 3)\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Until the end of all analysis I don't really want to look at the real test set results\n",
        "# I'm overwriting them to make sure I don't accidentally use them\n",
        "\n",
        "x_test = []\n",
        "y_test = []\n",
        "\n",
        "\n",
        "# I decide to take a small dataset - 2000 samples of the 60000, and use that to \n",
        "# create a TRAIN Set of up to 1000 samples, a VALIDATION Set of up to 1000 samples, and a FAKE-TEST set of the remaining 58000\n",
        "# After Analyzing the best \"Augmentation Effect\" I wil apply it to the \"REAL\" Test DataSet to see if it improved.\n",
        "\n",
        "\n",
        "# # Validation Set is 1000 --> 500 \n",
        "x_val = x_train[5000:6000]\n",
        "y_val = y_train[5000:6000]\n",
        "\n",
        "# #My FAKE Test Set is 58000\n",
        "x_test = x_train[6000:60000]\n",
        "y_test = y_train[6000:60000]\n",
        "\n",
        "\n",
        "# # Finally I change train dataset to first 1500\n",
        "x_train = x_train[0:5000]\n",
        "y_train = y_train[0:5000]\n",
        "\n",
        "hist= sn.histplot(y_train)\n",
        "print(hist)\n",
        "#My holdout Test Set after all the DOE is the original TEST set from dataset\n",
        "\n",
        "\n",
        "#print(\"Fashion MNIST has training size up to: \", y_train.shape, \", val set of , \", y_val.shape, \" and test set of \", y_test.shape)\n",
        "\n",
        "\n",
        "# Scale images to the [0, 1] range # put into preprocessing model step\n",
        "#x_train = x_train.astype(\"float32\") / 255\n",
        "#x_test = x_test.astype(\"float32\") / 255   \n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "x_val = np.expand_dims(x_val, -1)\n",
        "\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_val.shape[0], \"validation samples\")\n",
        "print(x_test.shape[0], \" test samples saved from the training set\")\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# Try to put in tensor flow shape\n",
        "x_val = tf.stack(x_val)\n",
        "y_val = tf.stack(y_val)\n",
        "\n",
        "\n",
        "# Define Manual Validation Set\n",
        "valid_set = (x_val, y_val)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AxesSubplot(0.125,0.125;0.775x0.755)\n",
            "x_train shape: (5000, 32, 32, 3, 1)\n",
            "5000 train samples\n",
            "1000 validation samples\n",
            "44000  test samples saved from the training set\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psp_7WmljrD4"
      },
      "source": [
        "Class 2 looks a bit underrepresented, class 7 looks overrepresented in first 1000.  I looked at 1500 and it seemed more balanced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3J-NWLSOUwr"
      },
      "source": [
        "## Image Augmentation Factors "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAkWq7-unsil"
      },
      "source": [
        "Augmentation_Building Function to build Data Augmentation Layer in Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVwm2mHKBWEr"
      },
      "source": [
        "def augmentation_building(flip, c, r, n, z, randseed=42, num_classes = 10, input_shape = input_shape):  \n",
        "\n",
        "  if flip == 0:\n",
        "    flip_layer      = layers.experimental.preprocessing.Rescaling(1./1, input_shape=(input_shape))\n",
        "  else:\n",
        "    flip_layer     = layers.experimental.preprocessing.RandomFlip(\"horizontal\", seed = randseed, name = \"FlipHorizontal\")\n",
        "\n",
        "  # if r == 0:\n",
        "  #   rotate_layer    = layers.experimental.preprocessing.Rescaling(1./1, input_shape=(input_shape), name = \"RotateOff\")\n",
        "  # else:\n",
        "  #   rotate_layer   = layers.experimental.preprocessing.RandomRotation(factor = r, seed = randseed, name = \"RotateOn\")\n",
        "\n",
        "  if c == 0:\n",
        "    contrast_layer  = layers.experimental.preprocessing.Rescaling(1./1, input_shape=(input_shape), name = \"ContrastOff\")\n",
        "  else:\n",
        "    contrast_layer = layers.experimental.preprocessing.RandomContrast(factor=c, seed = randseed, name = \"ContrastOn\") \n",
        "\n",
        "  if n == 0:\n",
        "    noise_layer     = layers.experimental.preprocessing.Rescaling(1./1, input_shape=(input_shape), name = \"NoiseOff\")\n",
        "  else:\n",
        "   noise_layer    = layers.GaussianNoise(n, name = \"GaussianNoise\")\n",
        "\n",
        "  if z == 0:\n",
        "    zoom_layer      = layers.experimental.preprocessing.Rescaling(1./1, input_shape=(input_shape), name = \"ZoomOff\")\n",
        "  else:\n",
        "    zoom_layer     = layers.experimental.preprocessing.RandomZoom(height_factor=z, fill_mode=\"constant\", fill_value=0.0, name=\"ZoomOn\")\n",
        "\n",
        "  \n",
        "  data_augmentation = tf.keras.Sequential([\n",
        "    flip_layer,  \n",
        "    #rotate_layer,  \n",
        "    contrast_layer, \n",
        "    noise_layer,\n",
        "    zoom_layer  \n",
        "  ])\n",
        " \n",
        "\n",
        "  model = keras.Sequential(\n",
        "  [\n",
        "      keras.Input(shape=input_shape),\n",
        "      layers.experimental.preprocessing.Rescaling(1./255, input_shape=(input_shape)),\n",
        "      data_augmentation,   \n",
        "      layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "      layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "      layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "      layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "      layers.Conv2D(128, kernel_size=(3, 3), activation=\"relu\"),\n",
        "      layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "      layers.Flatten(),\n",
        "      #layers.Dropout(0.5),\n",
        "      layers.Dense(num_classes, activation=\"softmax\")\n",
        "  ])\n",
        "  \n",
        "  return model\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfEAEpAFMm0W"
      },
      "source": [
        "Code to print the training-validation run plots by Accuracy and Loss \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSvz7WMvMmVT"
      },
      "source": [
        "def print_history(history):\n",
        "  print(history.history.keys())\n",
        "  plt.figure(counter+1)\n",
        "\n",
        "  # plt.subplot(211)\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.plot(history.history['val_accuracy'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'validation'])\n",
        "  plt.show()\n",
        "\n",
        "  # summarize history for loss  \n",
        "  plt.subplot(212)  \n",
        "  plt.plot(history.history['loss'])  \n",
        "  plt.plot(history.history['val_loss'])  \n",
        "  plt.title('model loss')  \n",
        "  plt.ylabel('loss')  \n",
        "  plt.xlabel('epoch')  \n",
        "  plt.legend(['train', 'validation'], loc='upper left')  \n",
        "  plt.show() "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0DcCArLSguX"
      },
      "source": [
        "# Run the Experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftmEQF7fjEBg"
      },
      "source": [
        "var_trainsize  = 20, 100 #, 500, 1000 #, 1500, 2500, 5000 \n",
        "#var_flip = 0, 1                     # 0 means no flip, 1 means horizontal flip\n",
        "var_contrast = 0, 0.05, 0.1, 0.15 # 0.001, 0.01, 0.1    # 0 means no contrast (I think) and 1.02 means contrast difference of 0.02  (I think)\n",
        "# var_rotate = 0, 0.1     #0.025, .05       # 0.5 means rotate between -5 and 5 degrees\n",
        "var_noise = 0, 0.05, .1  ,0.15       # 0 means no noise, 0.1 means 10% noise\n",
        "var_zoom = 0, 0.05        #0.05, .1\n",
        "randseed = 42 #, 123, 4321\n",
        "\n",
        "\n",
        "def recordmodel(model, t, currentscore, current_run_variables, score_dictionary):\n",
        "  if currentscore > score_dictionary[t]['score']:\n",
        "    modelfilename = str(\"model_best\")  + str(t) + str(\".h5\")\n",
        "    model.save_weights(modelfilename) \n",
        "    print(\"                                        \\t   * new record accuracy saved\")\n",
        "    score_dictionary[t]['score'] = currentscore\n",
        "    score_dictionary[t]['record'] = current_run_variables\n",
        "  \n",
        "\n",
        "def initialize_variables(t):\n",
        "  variable_name, variable_value, variable_record = str(\"best_\") + str(t) + str(\"_run_score\"), 0.1, \"\"\n",
        "  return variable_name, variable_value, variable_record\n",
        "\n",
        "# Initialize Score Keeper\n",
        "score_dictionary = {}\n",
        "for t in var_trainsize:\n",
        "    score_dictionary[t] = { 'score': 0.1, 'record': \"\" }\n",
        "\n",
        "# Initialize Baseline Score Keepers\n",
        "basescore = {}\n",
        "for t in var_trainsize:\n",
        "    basescore[t] = 0\n",
        "        \n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "id": "6eCq1qgX-aCK",
        "outputId": "4cf1d9bc-dbcd-4eef-83f6-05084d33e4bd"
      },
      "source": [
        "scorelist = [] \n",
        "\n",
        "counter = 0\n",
        "#for b in var_batches:\n",
        "#  for e in var_epochs:\n",
        "b = 128                    # how would this work for training sets less than this amount?\n",
        "e = 100\n",
        "r = 0 # no more rotate\n",
        "flip = 0 # no more flip\n",
        "\n",
        "#for randseed in randseeds:  # like the replicates in a test\n",
        "for t in var_trainsize:\n",
        "\n",
        "  new_x_train = x_train[0:t]  \n",
        "  new_y_train = y_train[0:t]\n",
        "  print(new_y_train.shape)\n",
        "\n",
        "#  for flip in var_flip:\n",
        "  for c in var_contrast:\n",
        "    # for r in var_rotate:\n",
        "      for n in var_noise:\n",
        "        for z in var_zoom:\n",
        "        \n",
        "          counter+=1\n",
        "          model = augmentation_building(flip, c, r, n, z, randseed=randseed)\n",
        "                \n",
        "          \n",
        "\n",
        "          callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
        "          model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "          model.save_weights('model_clear.h5') \n",
        "          model.load_weights('model_clear.h5')\n",
        "          \n",
        "          \n",
        "          start_time = datetime.now()\n",
        "          history = model.fit(new_x_train, new_y_train, batch_size=b, epochs=e, validation_data=valid_set, verbose=0, callbacks=callback)\n",
        "          #end_time = datetime.now()\n",
        "          #dur = end_time - start_time\n",
        "\n",
        "          score = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "          scorelist +=  [[counter, e, b,  t,  flip ,c,r,n,z,  score[1], score[0]]]\n",
        "          print(counter, b, e,  t, flip,c,r,n, z, \"\\t Accuracy: \", format(score[1], \".4f\"), \" Loss: \", format(score[0], \".4f\"))\n",
        "          \n",
        "          current_run_variables = \"Flip \" + str(flip) +  \", Contrast \" + str(c) +  \", Rotate \" + str(r) +  \", Noise \" + str(n) +  \", Zoom: \" + str(z) + \"RandSeed\" + str(randseed)\n",
        "        \n",
        "        \n",
        "          if flip ==0 and c ==0 and n==0 and z == 0:\n",
        "            print(\"Baseline Model Saved\")\n",
        "            modelbaseline = \"Baseline\" + str(t)  +  \".h5\"\n",
        "            model.save_weights(modelbaseline)\n",
        "            basescore[t] = score[1]\n",
        "            print_history(history)\n",
        "            \n",
        "          else:  \n",
        "          #Keep tabs on the best performing 100-run models\n",
        "            modelname =  \"model_\" + \"best\"   + str(t) + \".h5\"\n",
        "            recordmodel(model, t, score[1],  current_run_variables, score_dictionary)\n",
        "                        \n",
        "          filename = str(t) + 'T-' + str(flip) + 'F-' + str(c) + \"C-\" +  str(r) + \"R-\" +  str(n) + \"N-\" + str(z) + \"Z\" + str('.csv')\n",
        "\n",
        "\n",
        "\n",
        "np.savetxt(filename, scorelist, delimiter=',')\n",
        "print(\"File \", filename, \" saved at \", start_time)\n",
        "\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20, 10)\n",
            "1 128 100 20 0 0 0 0 0 \t Accuracy:  0.1596  Loss:  4.7789\n",
            "Baseline Model Saved\n",
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-c38885f64235>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m           \u001b[0;31m#dur = end_time - start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m           \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m           \u001b[0mscorelist\u001b[0m \u001b[0;34m+=\u001b[0m  \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mflip\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3036\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m-> 3038\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3458\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m   3459\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[0;32m-> 3460\u001b[0;31m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3349\u001b[0m     if (relaxed_arg_function is not None\n\u001b[1;32m   3350\u001b[0m         and all(_is_type_subset(x, y) for (x, y) in\n\u001b[0;32m-> 3351\u001b[0;31m                 zip(relaxed_arg_specs, arg_specs))):\n\u001b[0m\u001b[1;32m   3352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mrelaxed_arg_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3349\u001b[0m     if (relaxed_arg_function is not None\n\u001b[0;32m-> 3350\u001b[0;31m         and all(_is_type_subset(x, y) for (x, y) in\n\u001b[0m\u001b[1;32m   3351\u001b[0m                 zip(relaxed_arg_specs, arg_specs))):\n\u001b[1;32m   3352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mrelaxed_arg_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_is_type_subset\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_specific_compatible_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m     return (type(other) is type(self) and\n\u001b[0;32m--> 323\u001b[0;31m             self.__get_cmp_key() == other.__get_cmp_key())\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__ne__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_spec.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     88\u001b[0m     return (type(self) is type(other) and\n\u001b[1;32m     89\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m             and self._name == other._name)\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LB0DdajjBT2D"
      },
      "source": [
        "### Model Summary - model in for-loop (hide)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYlAkUTfHUME"
      },
      "source": [
        "tf.keras.utils.plot_model(\n",
        "    model,\n",
        "    to_file=\"model.png\",\n",
        "    show_shapes=False,\n",
        "    show_dtype=False,\n",
        "    show_layer_names=True,\n",
        "    rankdir=\"TB\",\n",
        "    expand_nested=False,\n",
        "    dpi=96,\n",
        "    layer_range=None,\n",
        ")\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCLKo7SgHa8J"
      },
      "source": [
        "Better Plot Model Option"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUwXcXiCHaVJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ohf_0rieSXC9"
      },
      "source": [
        "!pip install h5py==2.10.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_OXslKCOUw0"
      },
      "source": [
        "# Evaluate the trained model on TEST DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyqgW4Qyn3y5"
      },
      "source": [
        "LABEL_NAMES = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'AnkleBoots']\n",
        "\n",
        "modelnames = []\n",
        "for t in var_trainsize:  \n",
        "  modelfilename = str(\"model_best\")  + str(t) + str(\".h5\")\n",
        "  modelnames = modelnames + [modelfilename]\n",
        "\n",
        "\n",
        "basenames = []\n",
        "for t in var_trainsize:  \n",
        "  modelfilename = str(\"Baseline\")  + str(t) + str(\".h5\")\n",
        "  basenames = basenames + [modelfilename]\n",
        " \n",
        "y_test_reshape = np.argmax(y_test, axis=1) \n",
        "# Quick Check which model was better (Augmented or Base/Non-Augmented)\n",
        "for t in var_trainsize:\n",
        "  if basescore[t] >= score_dictionary[t]['score']:\n",
        "    print(\"Base \", t, \"has best Accuracy\", basescore[t])\n",
        "  else:\n",
        "    print(\"Augmented \", t, \"has best Accuracy,\", score_dictionary[t]['score'], \" compared to \", basescore[t], \"difference of \\t\", (score_dictionary[t]['score']-basescore[t]))\n",
        "\n",
        "\n",
        "# When Evaluating the Models on the Test/Holdout Data I want to make sure I'm not\n",
        "#  inadvertently adding a dataaugmentation step, I just want the testdata/holdoutdata to go through the weights.so i respecify the model architecture here\n",
        "  model = keras.Sequential(\n",
        "  [\n",
        "      keras.Input(shape=input_shape),\n",
        "      layers.experimental.preprocessing.Rescaling(1./255, input_shape=(input_shape)),\n",
        "    #  data_augmentation,   \n",
        "      layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "      layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "      layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "      layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "      layers.Conv2D(128, kernel_size=(3, 3), activation=\"relu\"),\n",
        "      layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "      layers.Flatten(),\n",
        "      #layers.Dropout(0.5),\n",
        "      layers.Dense(num_classes, activation=\"softmax\")\n",
        "  ])\n",
        "\n",
        "\n",
        "def makeconfusionmatrix(model, modelname, accuracy, tsize, otherinfo = \"\"):\n",
        "    model.load_weights(modelname)\n",
        "\n",
        "    predictions = model.predict(x_test)\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    \n",
        "    confusion_matrix = tf.math.confusion_matrix(y_test_reshape, predictions)  #First Variable is on VERTICAL, second Variable is on X HORIZONTAL\n",
        "    title = str(modelname) + str(\" Accuracy \" ) + str(round(accuracy, ndigits=4)) + str(otherinfo)\n",
        "\n",
        "    f, ax = plt.subplots(figsize=(5, 7), sharey = True)\n",
        "    sn.heatmap(\n",
        "        confusion_matrix,\n",
        "        annot=True,\n",
        "        linewidths=.5,\n",
        "        fmt=\"d\",\n",
        "        square=True\n",
        "        ,cmap=plt.cm.gray_r\n",
        "        ,cbar=False\n",
        "        ,xticklabels=LABEL_NAMES\n",
        "        ,yticklabels=LABEL_NAMES\n",
        "        #,display_labels=LABEL_NAMES\n",
        "        ,ax=ax\n",
        "\n",
        "    )\n",
        "    plt.title(title)\n",
        "    ax.set_ylabel('True Category')\n",
        "    ax.set_xlabel('Predictions')\n",
        "    plt.show()\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YobOk8sNTgip"
      },
      "source": [
        "In my first run, no data augmentation, 100 random samples of the Training Set, using 50% of that as the Validation Set, using a Batch Size of 50 and Epochs = 30, the resulting accuracy of the test-set is Test loss: 0.912209689617157\n",
        "Test accuracy: 0.6866999864578247"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ua25YRGNHg0S"
      },
      "source": [
        "## Confusion Matrix without the Diagonal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aRFTHeG1SkQ"
      },
      "source": [
        "def makeconfusionmatrixminusidentity(model, modelname, accuracy, tsize, otherinfo = \"\"):\n",
        "    model.load_weights(modelname)\n",
        "\n",
        "    predictions = model.predict(x_test)\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    \n",
        "    confusion_matrix = tf.math.confusion_matrix(y_test_reshape, predictions)  #First Variable is on VERTICAL, second Variable is on X HORIZONTAL\n",
        "    title = str(modelname) + str(\" Accuracy \" ) + str(round(accuracy, ndigits=4)) + str(otherinfo)\n",
        "\n",
        "\n",
        "    confusing_part_matrix= np.array(confusion_matrix)-np.identity(confusion_matrix.shape[0])*np.diag(confusion_matrix)\n",
        "    confusing_part_matrix = tf.convert_to_tensor(confusing_part_matrix)\n",
        "    title = str(modelname)\n",
        "\n",
        "    f, ax = plt.subplots(figsize=(9, 7))\n",
        "    sn.heatmap(\n",
        "        confusing_part_matrix,\n",
        "        annot=True,\n",
        "        linewidths=.5\n",
        "        ,fmt='.0f'\n",
        "        ,square=True\n",
        "        ,cmap=plt.cm.gray_r\n",
        "        ,cbar=True\n",
        "        ,vmax=2000\n",
        "        ,xticklabels=LABEL_NAMES\n",
        "        ,yticklabels=LABEL_NAMES\n",
        "        #,display_labels=LABEL_NAMES\n",
        "        #,ax=ax\n",
        "    )\n",
        "\n",
        "  \n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    ## find the max value of those remaining numbers\n",
        "    thisnumber=np.max(confusing_part_matrix)\n",
        "\n",
        "    # x_thisnumber=np.argmax(confusing_part_matrix,axis=0)\n",
        "    # y_thisnumber=np.argmax(confusing_part_matrix,axis=1)\n",
        "    # z_thisnumber=np.argmax(confusing_part_matrix)\n",
        "    # display(x_thisnumber,y_thisnumber)\n",
        "    # print(\"The worst the algorithm did is between \" confus)\n",
        "    z_thisnumber=np.argmax(confusing_part_matrix)\n",
        "    z_thisnumber\n",
        "    print(\"The algorithm misrecognizes \", thisnumber, \"  of class \" ,  LABEL_NAMES[np.math.floor(z_thisnumber/10)] , \" as class \",  LABEL_NAMES[z_thisnumber%10])\n",
        "\n",
        "\n",
        "    display(sum(sum(confusing_part_matrix)))\n",
        "\n",
        "\n",
        "for modelname, tsize, basename  in zip(modelnames, var_trainsize, basenames):\n",
        "  #makeconfusionmatrix(model, modelname, score_dictionary[tsize]['score'], tsize, otherinfo=str(score_dictionary[tsize]['record']))\n",
        "  #makeconfusionmatrix(model, basename, basescore[tsize], tsize)\n",
        "  makeconfusionmatrixminusidentity(model, modelname, score_dictionary[tsize]['score'], tsize, otherinfo=str(score_dictionary[tsize]['record']))\n",
        "  makeconfusionmatrixminusidentity(model, basename, basescore[tsize], tsize)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3V0jrX_Mmxl"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9K24O6nCMnPP"
      },
      "source": [
        "plt.imshow(x_test[0].reshape((28,28)), cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEPa4pHiy4fe"
      },
      "source": [
        "Evaluate the \"Winning Augmentations\" for Holdout Data"
      ]
    }
  ]
}